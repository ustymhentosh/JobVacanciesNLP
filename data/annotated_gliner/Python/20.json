{
  "classes": [
    "SKILL_HARD",
    "SKILL_SOFT",
    "ENGLISH_LEVEL",
    "DEGREE",
    "EXPERIENCE_LEVEL",
    "EXPERIENCE_YEARS",
    "BENEFIT",
    "LOCATION",
    "COMPANY",
    "ROLE"
  ],
  "annotations": [
    [
      "Senior Backend Engineer ‚Äî Data Infrastructure & Web Scraping\nüåç Location: remote\n\nWe‚Äôre seeking a backend engineer with deep expertise in web scraping and data\ninfrastructure to build the foundational systems with one of our partners, an\nIsraeli startup product.\n\nYou‚Äôll be responsible for designing and implementing scalable pipelines that\ncollect, process, and serve data from complex platforms at enterprise scale.\n\n Day-to-Day Responsibilities\n\n Develop large-scale scraping routines, tackling challenges of performance, accuracy, and source accessibility\n Create and optimize data processing pipelines in Python, structuring high-performance databases and queries (SQL)\n Work in AWS (cloud-native), with flexibility to adapt solutions to other clouds\n Participate in technical discussions with the founders, contributing to architectural and product decisions\n Apply creativity and critical thinking to solve unprecedented problems without ready-made playbooks\n\n Required Qualifications\n\nWeb Scraping Expertise:\n\n Proven experience with large-scale web scraping on complex platforms like Reddit or Wikipedia\n Skilled at traversing multi-level link structures and handling edge cases\n Ability to bypass anti-scraping measures and partial-access restrictions (books, journals, paywalls)\n Advanced scraping capabilities, including complex crawling and parsing of multiple formats\n\nBackend Development:\n\n Strong Python skills for backend processing, scripting, and automation\n Experience parsing, cleaning, and structuring data from APIs and scraped sources\n Proven ability to prepare large datasets accurately and completely, including small or hard-to-reach sources\n\nData & Infrastructure:\n\n SQL proficiency for querying, transforming, and database modeling\n Experience handling large volumes of data with low-latency and high-precision requirements\n Experience designing scalable data pipelines for collection, storage, and retrieval\n\nAPI Development:\n\n Experience building robust B2B APIs that expose processed datasets with layered metadata\n Understanding of performance optimization for enterprise-scale API delivery\n\nCloud Infrastructure:\n\n Experience with AWS (adaptable to other cloud platforms)\n Knowledge of cloud-native architecture and security best practices\n\n Nice to Have\n\n Familiarity with LLMs and Prompt Engineering for validating sources or assessing scrappability\n Experience with RPA and data collection automation\n Knowledge of JavaScript or other languages for specific integrations\n Understanding of distributed architecture and resilient system design\n Experience with natural language processing for content analysis\n Background in statistical modeling for trust scoring or similar applications\n\n Timeline & Impact\n\nTimeline: Minimum 6-month development cycle to deliver a production-ready\nMVP with enterprise customers including major search engines and AI platforms.\n\nImpact: The technical architecture you build must handle massive data\nprocessing, efficient cross-referencing, automated content verification, and\nenterprise-scale API delivery. Your work will directly enable AI systems\nworldwide to serve more reliable information.",
      {
        "entities": [
          [
            7,
            23,
            "ROLE"
          ],
          [
            73,
            79,
            "LOCATION"
          ],
          [
            97,
            113,
            "ROLE"
          ],
          [
            609,
            615,
            "SKILL_HARD"
          ],
          [
            669,
            672,
            "SKILL_HARD"
          ],
          [
            683,
            686,
            "SKILL_HARD"
          ],
          [
            1412,
            1418,
            "SKILL_HARD"
          ],
          [
            1694,
            1697,
            "SKILL_HARD"
          ],
          [
            2164,
            2167,
            "SKILL_HARD"
          ],
          [
            2402,
            2405,
            "SKILL_HARD"
          ],
          [
            2451,
            2461,
            "SKILL_HARD"
          ]
        ]
      }
    ]
  ]
}