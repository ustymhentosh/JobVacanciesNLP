{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "157bbce8",
   "metadata": {},
   "source": [
    "#### Scraping Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f7876805",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "77708dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_one_page_vacancies(html_text: str) -> list:\n",
    "    vacancies_lst = []\n",
    "    soup = BeautifulSoup(html_text, \"html.parser\")\n",
    "    vacancies = soup.find_all(class_ =\"l-vacancy\")\n",
    "    for v in vacancies:\n",
    "        title_el = v.select_one(\".vt\")\n",
    "        if title_el:\n",
    "            title = title_el.get_text(strip=True)\n",
    "            link = title_el.get(\"href\")\n",
    "            vacancies_lst.append({\"title\": title, \"link\": link})\n",
    "    return vacancies_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5eda266b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vacancies_list(url, how_many=100, auto_save=True, logs = True):\n",
    "    \"\"\"\n",
    "    Loads valancies titles and links from DOU\n",
    "    \"\"\"\n",
    "    all_vacancies = []\n",
    "    \n",
    "    base_url = url\n",
    "    ajax_url = f\"https://jobs.dou.ua/vacancies/xhr-load/?{base_url.split('?')[-1]}\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\",\n",
    "        \"Referer\": base_url, \n",
    "    }\n",
    "    session = requests.Session()\n",
    "    session.headers.update(headers)\n",
    "\n",
    "    resp = session.get(base_url)\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "    vs = parse_one_page_vacancies(resp.text)\n",
    "    all_vacancies.extend(vs)\n",
    "\n",
    "    csrf_token = soup.select_one(\"input[name=csrfmiddlewaretoken]\")[\"value\"]\n",
    "    print(\"CSRF token:\", csrf_token)\n",
    "\n",
    "    count = 20\n",
    "    cancel = False\n",
    "    while len(all_vacancies) < how_many:\n",
    "        time.sleep(2 + random.randint(1, 2) * random.random())\n",
    "        data = {\n",
    "                \"csrfmiddlewaretoken\": csrf_token,\n",
    "                \"count\": count\n",
    "            }\n",
    "        resp_2 = session.post(ajax_url, data=data)\n",
    "        if not resp_2.text.strip():\n",
    "            break\n",
    "        text_2 = json.loads(resp_2.text)[\"html\"]\n",
    "        vs_new = parse_one_page_vacancies(text_2)\n",
    "        if len(vs_new) <= 0:\n",
    "            break\n",
    "        all_vacancies.extend(vs_new)\n",
    "        \n",
    "        # auto save\n",
    "        if auto_save:\n",
    "            with open(f\"{url.split('=')[-1].split('/')[-1]}.json\", \"w\") as f:\n",
    "                json.dump(all_vacancies, f)\n",
    "        \n",
    "        if logs:\n",
    "            print(\"downloaded:\", len(all_vacancies))\n",
    "        \n",
    "    \n",
    "        count += 20\n",
    "    \n",
    "    return all_vacancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9b2540",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://jobs.dou.ua/vacancies/?category=Java\",\n",
    "    \"https://jobs.dou.ua/vacancies/?category=Python\",\n",
    "    \"https://jobs.dou.ua/vacancies/?category=.NET\",\n",
    "    \"https://jobs.dou.ua/vacancies/?category=AI/ML\",\n",
    "    \"https://jobs.dou.ua/vacancies/?category=PHP\",\n",
    "    \"https://jobs.dou.ua/vacancies/?category=Golang\",\n",
    "    \"https://jobs.dou.ua/vacancies/?category=iOS/macOS\",\n",
    "    \"https://jobs.dou.ua/vacancies/?category=Android\",\n",
    "    \"https://jobs.dou.ua/vacancies/?category=C%2B%2B\",\n",
    "    \"https://jobs.dou.ua/vacancies/?category=QA\",\n",
    "    \"https://jobs.dou.ua/vacancies/?category=Front%20End\",\n",
    "    \"https://jobs.dou.ua/vacancies/?category=Project%20Manager\",\n",
    "    \"https://jobs.dou.ua/vacancies/?category=Node.js\",\n",
    "    \"https://jobs.dou.ua/vacancies/?category=Product%20Manager\",\n",
    "    \"https://jobs.dou.ua/vacancies/?category=Design\",\n",
    "    \"https://jobs.dou.ua/vacancies/?category=Sales\",\n",
    "    \"https://jobs.dou.ua/vacancies/?category=Marketing\",\n",
    "    \"https://jobs.dou.ua/vacancies/?category=DevOps\",\n",
    "    \"https://jobs.dou.ua/vacancies/?search=govtech\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "784bce5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI/ML\n",
      "CSRF token: sE9zavYDPPwAWJk9AhBqDb0qmK5WAVapjNRyUZIcmY3v72uCNyl9GBTqWOpwUUs6\n",
      "downloaded: 60\n",
      "downloaded: 100\n",
      "PHP\n",
      "CSRF token: O86iEvj1Nw0j3dknupOkDf5Uliv8OPkdHRut9ULoE7IHT3i21xTPXGcpnJxQeqTI\n",
      "downloaded: 60\n",
      "downloaded: 100\n",
      "Golang\n",
      "CSRF token: iEWYAyDI0K1vOZIr4y0HXbtxWNOAJmEouRS2rLStbDTLwrTc2Lekj87lWhJyfSF6\n",
      "downloaded: 50\n",
      "downloaded: 60\n",
      "iOS/macOS\n",
      "CSRF token: aCUp4VvJf8qXbYRGTQuVAtjVDLSsoeTpRe4KnrfF32KYv0Y9QJx8FoghHVpL4eIS\n",
      "downloaded: 56\n",
      "downloaded: 72\n",
      "Android\n",
      "CSRF token: swWCfLi48rYJA6G3UCBCYIOVlscPa0dIJ55Fp1zSYmzjfgWk3kZgWkVB2FFGdDT0\n",
      "downloaded: 53\n",
      "downloaded: 66\n",
      "C%2B%2B\n",
      "CSRF token: Fu1fqBjsBDdjQhUz2MMglL81GJYXqph5nXohl7TiqwPX0wNvwJlRSQuiF0SYj5AX\n",
      "downloaded: 60\n",
      "downloaded: 100\n",
      "QA\n",
      "CSRF token: yYP4cNiP41d0RqJ7PI1wlCetaH2FxN4Z15Emh7P5b2pJPlZ5daapFivJ3AgghxyY\n",
      "downloaded: 60\n",
      "downloaded: 100\n",
      "Front%20End\n",
      "CSRF token: RaomfHtgyGuggrzc9YsnQk1isCAQ2SY4Ill2O8SBmn7WZN0ZvAAdUWOsfuNQpFyj\n",
      "downloaded: 60\n",
      "downloaded: 100\n",
      "Project%20Manager\n",
      "CSRF token: 5t8PjOzfKRgobPb6xkL630erlaP6uqXvgOynlpQigv5t4i3o6p8MhrQ0z3sKl7NG\n",
      "downloaded: 60\n",
      "downloaded: 100\n",
      "Node.js\n",
      "CSRF token: T0v1NguRFBWa6oYuHJkZ6nreOjIvI3fIZqAjGefhj7YRw2XZF1AN3qatkbYsw6MC\n",
      "downloaded: 60\n",
      "downloaded: 100\n",
      "Product%20Manager\n",
      "CSRF token: PZaI0UyN7wVXp3nKwTgs5dTyWVDtQuEQHCt0PALAlAX1jVKhh4GjqxfZrvAsmCjp\n",
      "downloaded: 60\n",
      "downloaded: 100\n",
      "Design\n",
      "CSRF token: zXeevWsqkSmfsikNnOhIdahd7dhwBJphrgjJRxXqJeX9KRYRsshDFNDVUJcvvD3n\n",
      "downloaded: 60\n",
      "downloaded: 100\n",
      "Sales\n",
      "CSRF token: D5tR5EmVd3HvV7Lt1m0reClmSP4oF03WJCCc9bC7mfmd9iktkPo3imagY33CLsk6\n",
      "downloaded: 60\n",
      "downloaded: 100\n",
      "Marketing\n",
      "CSRF token: z95XErkCiCrrZ3xofuJ6fQ7P8i3KhddGkPidqrrUcox4WjvIEJuHar6Yp8QoqBur\n",
      "downloaded: 60\n",
      "downloaded: 100\n",
      "DevOps\n",
      "CSRF token: dmO4FuaMnmeKKaRbXSI9g2GGbdmw3UP26GRWtikeu6fUk5nPSIoRdmQPCnQ2nFDk\n",
      "downloaded: 60\n",
      "downloaded: 100\n",
      "govtech\n",
      "CSRF token: 6HxHtZoiYHrr96m5uFkS48rpWO3ZUJ0uxjoTMkedOKZR0uAoHgKAHXE4QoN5FZVS\n",
      "downloaded: 60\n",
      "downloaded: 100\n"
     ]
    }
   ],
   "source": [
    "for url in urls:\n",
    "    print(url.split('=')[-1])\n",
    "    all_vacancies = get_vacancies_list(url, 100)\n",
    "    with open(f\"./data/{url.split('=')[-1].split('/')[-1]}.json\", \"w\") as f:\n",
    "        json.dump(all_vacancies, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b476f78",
   "metadata": {},
   "source": [
    "#### Vacancies Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "2facc989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import html2text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "0c736aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_vacancy_text(url: str) -> str:\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0 Safari/537.36\",\n",
    "    }\n",
    "    resp = requests.get(url, headers=headers)\n",
    "    resp.raise_for_status()\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "    container = soup.find(\"div\", class_=\"b-typo vacancy-section\")\n",
    "    \n",
    "    markdown_text = html2text.html2text(str(container))\n",
    "    markdown_text = markdown_text.strip()\n",
    "    return markdown_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "7728d123",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "4e34888d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "72it [02:11,  1.83s/it]\n",
      "100it [03:03,  1.84s/it]\n",
      "100it [02:59,  1.80s/it]\n",
      "100it [03:03,  1.84s/it]\n",
      "100it [02:58,  1.78s/it]\n",
      "100it [03:07,  1.88s/it]\n",
      "100it [02:51,  1.72s/it]\n",
      "100it [02:59,  1.80s/it]\n",
      "100it [02:58,  1.79s/it]\n",
      "100it [02:54,  1.74s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in os.listdir(\"./data\"):\n",
    "    name = i.split(\".\")[0]\n",
    "    os.makedirs(f\"./texts/{name}/\", exist_ok=True)\n",
    "    \n",
    "    with open(f\"./data/{i}\", \"r\", encoding=\"utf-8\") as f:\n",
    "        vacancies = json.load(f)\n",
    "\n",
    "    for i, vanacy in tqdm(enumerate(vacancies)):\n",
    "        link = vanacy[\"link\"]\n",
    "        text = extract_vacancy_text(link)\n",
    "        \n",
    "        # rate handle\n",
    "        time.sleep(1 + random.randint(0, 2) * random.random())\n",
    "        \n",
    "        with open(f\"./texts/{name}/{i}.md\", \"w\", encoding=\"utf-8\") as fw:\n",
    "            fw.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabacb40",
   "metadata": {},
   "source": [
    "#### Fix Indexs and Unicode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "93844ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Android.json\n",
      "Cpp.json\n",
      "Design.json\n",
      "DevOps.json\n",
      "dotNET.json\n",
      "FrontEnd.json\n",
      "Golang.json\n",
      "govtech.json\n",
      "Java.json\n",
      "macOS.json\n",
      "Marketing.json\n",
      "ML.json\n",
      "Node.json\n",
      "PHP.json\n",
      "ProductManager.json\n",
      "ProjectManager.json\n",
      "Python.json\n",
      "QA.json\n",
      "Sales.json\n"
     ]
    }
   ],
   "source": [
    "for i in os.listdir(\"./data-done\"):\n",
    "\n",
    "    with open(f\"data-done/{i}\", \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    for j, item in enumerate(data):\n",
    "        item[\"title\"] = item[\"title\"]\n",
    "        item[\"index\"] = j\n",
    "\n",
    "    with open(f\"data/{i}\", \"w\", encoding=\"utf-8\") as fl:\n",
    "        json.dump(data, fl, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
