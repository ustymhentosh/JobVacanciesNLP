{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e228cc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from gliner2 import GLiNER2\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7b6718d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path.cwd().resolve().parents[1]\n",
    "CLEANTED_TEXTS_DIR = os.path.join(BASE_DIR, 'data', 'texts_ner_cleaned_standard')\n",
    "SCHEMA_PATH = os.path.join(BASE_DIR, 'data', 'annotated_manual', 'schema.json')\n",
    "FOLDER_NAMES = ['Python', 'ML', 'Android', 'DevOps', 'dotNET', 'FrontEnd', 'Golang', 'Java', 'macOS', 'Node', 'PHP']\n",
    "SAVE_DIR = os.path.join(BASE_DIR, 'data', 'cleaned_standard_annotated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "832613f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "702\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Cleans unwanted special characters from text, including '*', '#', and '‚óè',\n",
    "    normalizes spaces and newlines, and trims the text.\n",
    "    \"\"\"\n",
    "    # Remove bullet symbols anywhere in text\n",
    "    text = re.sub(r'[\\*\\#‚óè]', '', text)\n",
    "    # Normalize multiple spaces/tabs to single space\n",
    "    text = re.sub(r'[ \\t]+', ' ', text)\n",
    "    # Normalize multiple newlines to max two newlines\n",
    "    text = re.sub(r'\\n{3,}', '\\n\\n', text)\n",
    "    # Strip leading/trailing whitespace\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "texts = []\n",
    "for folder in FOLDER_NAMES:\n",
    "    folder_path = os.path.join(CLEANTED_TEXTS_DIR, folder)\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith('.txt'):\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            with open(file_path, encoding='utf-8') as f:\n",
    "                raw_text = f.read()\n",
    "            # cleaned = clean_text(raw_text)\n",
    "            texts.append({'filename': f\"{folder}/{file}\", 'text': raw_text})\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6afc2126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SKILL_HARD': \"Specific technical tools, programming languages, frameworks, or methodologies. Examples: 'Python', 'React.js', 'Docker', 'machine learning', 'REST API', 'CI/CD'\",\n",
       " 'SKILL_SOFT': \"Personal, communication, or team-related abilities that describe behavioral or interpersonal skills. Examples: 'problem-solving', 'team player', 'attention to detail', 'leadership'\",\n",
       " 'ENGLISH_LEVEL': \"Any explicit or implied mention of English proficiency or fluency level. Examples: 'Upper-Intermediate', 'fluent English', 'B2 level', 'advanced English communication'\",\n",
       " 'DEGREE': \"Formal education degrees or academic qualifications. Examples: 'Bachelor‚Äôs degree', 'Master‚Äôs in Computer Science', 'PhD in Engineering'\",\n",
       " 'EXPERIENCE_LEVEL': \"Seniority or professional rank associated with the role. Examples: 'Junior', 'Middle', 'Senior', 'Lead', 'Intern'\",\n",
       " 'EXPERIENCE_YEARS': \"Duration or number of years of experience required or mentioned. Examples: '3+ years', 'at least two years'\",\n",
       " 'BENEFIT': \"Offered perks, bonuses, or employment benefits and work conditions by company. Examples: 'medical insurance', 'flexible schedule', 'remote work', 'paid vacation', 'stock options'\",\n",
       " 'LOCATION': \"Mention of workplace location or work formats. Examples: 'Kyiv', 'Lviv', 'remote', 'Poland', 'hybrid'\",\n",
       " 'COMPANY_NAME': \"Official company or employer names only; must be a real proper noun. Examples: 'Google', 'EPAM Systems', 'SoftServe'\",\n",
       " 'ROLE': \"Job title or position name describing the primary role. Examples: 'Frontend Developer', 'DevOps Engineer', 'Data Scientist'\"}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(SCHEMA_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    labels = json.load(f)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c188efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üß†  Model Configuration\n",
      "============================================================\n",
      "Encoder model      : microsoft/deberta-v3-large\n",
      "Counting layer     : count_lstm\n",
      "Token pooling      : first\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "model = GLiNER2.from_pretrained(\"fastino/gliner2-large-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9883cda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities:   0%|          | 0/702 [00:00<?, ?it/s]You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "Extracting entities: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 702/702 [3:46:37<00:00, 19.37s/it]  \n"
     ]
    }
   ],
   "source": [
    "def assign_offsets(text, entities):\n",
    "    \"\"\"\n",
    "    Assign start/end offsets for each entity mention in text,\n",
    "    returning a list of (start, end, label) tuples sorted by start.\n",
    "    \"\"\"\n",
    "    spans = []\n",
    "    seen_spans = set()\n",
    "    \n",
    "    for ent in entities:\n",
    "        ent_text = ent['text'].strip()\n",
    "        label = ent['label'].upper()\n",
    "        if not ent_text:\n",
    "            continue\n",
    "        \n",
    "        # Word boundary regex for exact match, case-insensitive\n",
    "        pattern = r'\\b' + re.escape(ent_text) + r'\\b'\n",
    "        \n",
    "        for match in re.finditer(pattern, text, flags=re.IGNORECASE):\n",
    "            span = (match.start(), match.end())\n",
    "            if span not in seen_spans:\n",
    "                seen_spans.add(span)\n",
    "                spans.append((match.start(), match.end(), label))\n",
    "    \n",
    "    # Sort spans by start position\n",
    "    spans = sorted(spans, key=lambda x: x[0])\n",
    "    return spans\n",
    "\n",
    "\n",
    "def dict_to_entity_list(entities_dict):\n",
    "    entities_list = []\n",
    "    for label, texts in entities_dict.items():\n",
    "        for text in texts:\n",
    "            entities_list.append({\"text\": text, \"label\": label})\n",
    "    return entities_list\n",
    "\n",
    "annotations = []\n",
    "\n",
    "for item in tqdm(texts, desc='Extracting entities'):\n",
    "    result = model.extract_entities(item[\"text\"], labels)\n",
    "    entities_dict = result.get('entities', result)\n",
    "    entity_list = dict_to_entity_list(entities_dict)\n",
    "    entities_with_offsets = assign_offsets(item[\"text\"], entity_list)\n",
    "    annotations.append({\n",
    "        \"filename\": item[\"filename\"],\n",
    "        \"text\": item[\"text\"],\n",
    "        \"entities\": entities_with_offsets\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a908f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filename': 'Python/0.txt',\n",
       " 'text': 'Middle/Senior Full-Stack Engineer ‚Äî SL\\nFaria is a forward-thinking company that consistently delivers new features\\nand is passionate about staying ahead of the competition. Every day is\\ndifferent, and you will be challenged to think creatively and innovate within\\na multi-disciplined team of talented people. We‚Äôre a great team to work with,\\nseriously committed to doing our best work, and we value individuals who can\\nwork well as part of a team.\\n\\nWe are seeking a Middle/Senior Full-Stack Engineer to join the development\\nteam of the SpotLight application, where you will develop features across the\\nfull SpotLight technology stack, working on both data platform integration and\\nuser interface components under the guidance of the Lead Engineer.\\n\\nKey Responsibilities\\n\\nImplement dashboard features requiring both back-end data processing and front-end visualization.\\nDevelop API endpoints for educational data analytics functionality\\nSupport data extraction and transformation processes\\nCollaborate on cross-product data integration (ManageBac+, OpenApply, SchoolsBuddy)\\nContribute to technical documentation and development processes\\n\\nRequired Technical Skills\\n\\n3-5+ years full-stack development experience with:\\nBack-end: Python, Ruby, or Elixir, SQL, and database design\\nFront-end: JavaScript, React or Vue.js, data visualization libraries\\nIntegration: RESTful API development, third-party system integration\\nDatabase: PostgreSQL, data modeling, performance optimization\\nExperience with cloud platforms (AWS preferred) and modern development practices\\nUnderstanding of data security and privacy requirements\\n\\nPreferred Qualifications\\n\\nEducational technology or student information system development experience\\nAnalytics platform or business intelligence tool development\\nExperience with regulated data environments and compliance requirements\\nBenefits\\n\\nCompensation ‚Äî Competitive salary and opportunities for career development (B2B)\\nHealthcare ‚Äî Comprehensive medical coverage by LuxMed (UNIQA for the UA)\\nVacation ‚Äî We support work/life balance and offer generous Annual leave and Public Holidays\\nWellbeing Resources ‚Äî Faria encourages team members to lead healthy lifestyles and provides recurring monthly Health and Wellness benefits\\nLearning ‚Äî We encourage continued education, providing an online learning platform, unlimited book purchases, and diverse internal and external training programs.\\nTeam ‚Äî Friendly atmosphere, group activities, and corporate events\\nEquipment ‚Äî MacBook Pro or another laptop of your specification, peripherals, and displays included\\nOffice ‚Äî Small but cozy office in Krakow(PL) or Ivano-Frankivsk(UA) for your convenience',\n",
       " 'entities': [(0, 13, 'EXPERIENCE_LEVEL'),\n",
       "  (0, 6, 'EXPERIENCE_LEVEL'),\n",
       "  (7, 13, 'EXPERIENCE_LEVEL'),\n",
       "  (14, 33, 'ROLE'),\n",
       "  (39, 44, 'COMPANY_NAME'),\n",
       "  (466, 479, 'EXPERIENCE_LEVEL'),\n",
       "  (466, 472, 'EXPERIENCE_LEVEL'),\n",
       "  (473, 479, 'EXPERIENCE_LEVEL'),\n",
       "  (480, 499, 'ROLE'),\n",
       "  (733, 737, 'EXPERIENCE_LEVEL'),\n",
       "  (1165, 1175, 'EXPERIENCE_YEARS'),\n",
       "  (1226, 1232, 'SKILL_HARD'),\n",
       "  (1234, 1238, 'SKILL_HARD'),\n",
       "  (1243, 1249, 'SKILL_HARD'),\n",
       "  (1251, 1254, 'SKILL_HARD'),\n",
       "  (1287, 1297, 'SKILL_HARD'),\n",
       "  (1299, 1304, 'SKILL_HARD'),\n",
       "  (1308, 1314, 'SKILL_HARD'),\n",
       "  (1358, 1369, 'SKILL_HARD'),\n",
       "  (1424, 1434, 'SKILL_HARD'),\n",
       "  (1509, 1512, 'SKILL_HARD'),\n",
       "  (1859, 1871, 'BENEFIT'),\n",
       "  (1940, 1950, 'BENEFIT'),\n",
       "  (1967, 1983, 'BENEFIT'),\n",
       "  (2013, 2021, 'BENEFIT'),\n",
       "  (2105, 2124, 'BENEFIT'),\n",
       "  (2127, 2132, 'COMPANY_NAME'),\n",
       "  (2160, 2164, 'EXPERIENCE_LEVEL'),\n",
       "  (2244, 2252, 'BENEFIT'),\n",
       "  (2309, 2317, 'BENEFIT'),\n",
       "  (2608, 2614, 'LOCATION'),\n",
       "  (2622, 2637, 'LOCATION')]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9c9137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in FOLDER_NAMES:\n",
    "    output_folder = os.path.join(SAVE_DIR, folder)\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for ann in annotations:\n",
    "    # Extract folder from filename, e.g. 'Python/file.txt' ‚Üí 'Python'\n",
    "    folder = ann['filename'].split('/')[0]\n",
    "    output_folder = os.path.join(SAVE_DIR, folder)\n",
    "    filename_json = os.path.basename(ann['filename']).replace('.txt', '.json')\n",
    "    output_path = os.path.join(output_folder, filename_json)\n",
    "\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(ann, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45126c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROLE\n",
      " - Golang Engineer\n",
      " - Go Engineer\n",
      "COMPANY_NAME\n",
      " - Solidgate\n",
      " - Solidgate\n",
      " - Solidgate\n",
      " - Solidgate\n",
      " - Solidgate\n",
      "SKILL_HARD\n",
      " - Go\n",
      " - Go\n",
      " - PostgreSQL\n",
      " - microservices\n",
      " - Apache Kafka\n",
      " - RabbitMQ\n",
      " - AWS\n",
      " - CI/CD\n",
      " - CI/CD\n",
      "EXPERIENCE_YEARS\n",
      " - 3+ years\n",
      " - 1.5+ years\n",
      "SKILL_SOFT\n",
      " - decision-making skills\n",
      "BENEFIT\n",
      " - 30+ days off\n",
      " - unlimited sick leave\n",
      " - free office meals\n",
      " - health coverage\n",
      " - Apple gear\n",
      " - conferences\n",
      " - wellness benefits\n"
     ]
    }
   ],
   "source": [
    "file = annotations[423]\n",
    "entities = file['entities']\n",
    "by_class = {}\n",
    "text = file['text']\n",
    "for start, end, label in entities:\n",
    "    span = text[start:end]\n",
    "    by_class.setdefault(label, []).append(span)\n",
    "\n",
    "for label, words in by_class.items():\n",
    "    print(label)\n",
    "    for w in words:\n",
    "        print(' -', w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ffdba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for folder in FOLDER_NAMES:\n",
    "#     os.makedirs(os.path.join(SAVE_DIR, folder), exist_ok=True)\n",
    "\n",
    "# for ann in annotations:\n",
    "#     folder = ann['filename'].split('/')[0]\n",
    "#     output_folder = os.path.join(SAVE_DIR, folder)\n",
    "#     filename_json = os.path.basename(ann['filename']).replace('.txt', '.json')\n",
    "#     output_path = os.path.join(output_folder, filename_json)\n",
    "\n",
    "#     data_to_save = {\n",
    "#         \"classes\": list(labels.keys()),\n",
    "#         \"annotations\": [\n",
    "#             [\n",
    "#                 ann[\"text\"],\n",
    "#                 {\"entities\": [[start, end, label] for start, end, label in ann[\"entities\"]]}\n",
    "#             ]\n",
    "#         ]\n",
    "#     }\n",
    "\n",
    "#     with open(output_path, 'w', encoding='utf-8') as f:\n",
    "#         json.dump(data_to_save, f, ensure_ascii=False, indent=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
